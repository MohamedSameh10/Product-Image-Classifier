{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trovp9hjv8cP"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tew0eYsSma3A"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m2Eq3kSwI9Z"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOY8NK7l-Afs"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Data/Slash/'\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "\n",
        "    image_path = os.path.join(folder_path, filename)\n",
        "    image = cv.imread(image_path)\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    if image is not None:\n",
        "        image = image.reshape((1,) + image.shape)\n",
        "\n",
        "        augment_iter = datagen.flow(image, batch_size=1, save_to_dir=folder_path, save_prefix='aug_', save_format='jpg')\n",
        "\n",
        "        num_augmented_images = 10\n",
        "        for _ in range(num_augmented_images):\n",
        "            next(augment_iter)\n",
        "    else:\n",
        "        print(\"Error loading image:\", image_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrBblfagwPRJ"
      },
      "source": [
        "## Data Loading and Dataset Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Ws_uS0nc0fS"
      },
      "outputs": [],
      "source": [
        "def load_dataset(folder_path):\n",
        "    images = []\n",
        "    labels_str = []\n",
        "    labels_names=[]\n",
        "\n",
        "    for class_name in os.listdir(folder_path):\n",
        "        class_folder = os.path.join(folder_path, class_name)\n",
        "\n",
        "        if os.path.isdir(class_folder):\n",
        "            print(\"Processing class:\", class_name)\n",
        "\n",
        "            for image_name in os.listdir(class_folder):\n",
        "                image_path = os.path.join(class_folder, image_name)\n",
        "\n",
        "                image = cv.imread(image_path)\n",
        "                if image is not None:\n",
        "                    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "                    image = cv.resize(image, (256, 256))\n",
        "                    images.append(image)\n",
        "                    labels_str.append(class_name)\n",
        "                else:\n",
        "                    print(\"Error loading image:\", image_path)\n",
        "\n",
        "    images = np.array(images)/255.0\n",
        "    labels_str = np.array(labels_str)\n",
        "\n",
        "    #print(images.shape)\n",
        "    #print(labels_str)\n",
        "\n",
        "    label_to_index = {label: index for index, label in enumerate(np.unique(labels_str))}\n",
        "    print(label_to_index)\n",
        "    labels_names=list(label_to_index.keys())\n",
        "    labels = np.array([label_to_index[label] for label in labels_str])\n",
        "    #print(labels)\n",
        "    # One-hot encode numerical labels\n",
        "    num_classes = len(label_to_index)\n",
        "    labels_one_hot = tf.one_hot(labels, num_classes)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels_one_hot))\n",
        "\n",
        "    return dataset, labels_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oSTA_inmNYxI"
      },
      "outputs": [],
      "source": [
        "folder_path='/content/drive/MyDrive/Data/Slash/web_scrapping'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LzwIt7ldPxi"
      },
      "outputs": [],
      "source": [
        "dataset, labels_names = load_dataset(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swdcy-OrMkPx"
      },
      "outputs": [],
      "source": [
        "labels_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fMq9uu9gLPuC"
      },
      "outputs": [],
      "source": [
        "dataset_length = tf.data.experimental.cardinality(dataset).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ5QTh06LhdK"
      },
      "outputs": [],
      "source": [
        "dataset_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Gn2BVd-NLCqS"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(buffer_size=dataset_length)\n",
        "dataset = dataset.shuffle(buffer_size=dataset_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X4UOJ56rI6mk"
      },
      "outputs": [],
      "source": [
        "def plot_images(dataset, num_images=5):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i, (image, label) in enumerate(dataset.take(num_images)):\n",
        "        plt.subplot(1, num_images, i+1)\n",
        "        plt.imshow(image.numpy())\n",
        "        plt.title(f'Label: {labels_names[np.argmax(label.numpy())]}')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1B12hyMI6j8"
      },
      "outputs": [],
      "source": [
        "plot_images(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-UImsbIJzS9l"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.shuffle(buffer_size=len(dataset))\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_test_dataset = dataset.skip(train_size)\n",
        "val_dataset = val_test_dataset.take(val_size)\n",
        "test_dataset = val_test_dataset.skip(val_size)\n",
        "\n",
        "batch_size = 4\n",
        "epochs=20\n",
        "\n",
        "num_classes=len(labels_names)\n",
        "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuUZ49cOK31G"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yCsljwOQO_i"
      },
      "source": [
        "# Creating The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q32TrjALD2C5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlKn22IGD5-B"
      },
      "outputs": [],
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "D9-doJFZ0F2n"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    min_delta=0.001,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yIHYEkLlD8iy"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHc1V0vxDwei"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUFludeUEA4h"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLUvlo0pHYhh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred_prob = []\n",
        "y_true = []\n",
        "\n",
        "for x_batch, y_batch in test_dataset:\n",
        "    batch_pred_prob = model.predict(x_batch)\n",
        "    y_pred_prob.extend(batch_pred_prob)\n",
        "    y_true.extend(tf.argmax(y_batch, axis=1).numpy())\n",
        "\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GM46e-by0gRe"
      },
      "outputs": [],
      "source": [
        "# model_path = '/content/drive/MyDrive/Data/Slash/model'\n",
        "\n",
        "# model.save(model_path+'model_file.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YmxrItONJAtI"
      },
      "outputs": [],
      "source": [
        "img=cv.imread('/content/drive/MyDrive/Data/Slash/xxl-rblksn-granat-inc-original-imag88p8gvth4hmb.webp')\n",
        "img=cv.resize(img,(256,256))\n",
        "img=cv.cvtColor(img, cv.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPgsfFxfMCEk"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SH9fU29HKuF0"
      },
      "outputs": [],
      "source": [
        "img=tf.cast(img, tf.float32) / 255.0\n",
        "img = tf.expand_dims(img, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ucr3U9FKpyl"
      },
      "outputs": [],
      "source": [
        "predictions=model(img)\n",
        "probabilities = tf.nn.softmax(predictions)\n",
        "print(labels_names[np.argmax(probabilities.numpy())])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61p4Ef6V9c9a"
      },
      "outputs": [],
      "source": [
        "labels_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "49XnxbgKKr3E"
      },
      "outputs": [],
      "source": [
        "# # !zip -r /content/model.zip /content/model.pt\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"model.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3m2Eq3kSwI9Z",
        "WrBblfagwPRJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}